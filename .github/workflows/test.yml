# GitHub Actions workflow for testing and code quality
#
# This workflow implements the Au-Zone SPS v2.3 testing patterns:
#   - Multi-platform coverage testing (x86_64, aarch64, on-target hardware)
#   - Three-phase on-target testing pattern (build -> test -> process)
#   - Full coverage collection (Rust + Python) with profiling builds
#   - SonarCloud static analysis and coverage aggregation
#   - Hardware benchmarks on target (imx8mp)
#
# Build Configuration:
#   - Cargo profile: profiling (inherits release, optimized with debug symbols)
#   - Python bindings: Built with maturin develop using profiling profile
#   - Coverage: cargo-llvm-cov for Rust, slipcover for Python
#
# Action Versions (hash-pinned per SPS v2.1):
# - actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5 (v4)
# - actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065 (v5)
# - actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 (v4)
# - actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093 (v4)
# - dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b (stable)
# - Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5 (v2.8.2)
# - taiki-e/install-action@493d7f216ecab2af0602481ce809ab2c72836fa1 (v2.62.62)
# - SonarSource/sonarqube-scan-action@fd88b7d7ccbaefd23d8f36f73b59db7a3d246602 (v6.0.0)
# - EnricoMi/publish-unit-test-result-action@34d7c956a59aed1bfebf31df77b8de55db9bbaaf (v2.21.0)
#
# Runner Notes:
# - ubuntu-22.04: Standard GitHub-hosted runner (x86_64)
# - ubuntu-22.04-arm-private: GitHub Private ARM64 runner (for private repos)
# - nxp-imx8mp-latest: NXP i.MX 8M Plus EVK - test-only runner (NO toolchain)
#
# Build Strategy:
# - x86_64 and aarch64 builds happen on GitHub-hosted/managed runners
# - imx8mp runner downloads aarch64 artifacts and runs tests only
# - Coverage processing happens on ubuntu-22.04-arm-private (same toolchain as build)
#
# Coverage Strategy:
# - Each platform runs tests independently and generates coverage
# - Coverage artifacts are uploaded from all platforms
# - Dedicated process job converts hardware coverage (gcda/profraw) to reports
# - SonarCloud job downloads and aggregates all coverage reports

name: Test

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1
  PYTHON_VERSION: '3.11'

jobs:
  # ===========================================================================
  # Checkout LFS files (on ubuntu-22.04 which has git-lfs)
  # ===========================================================================
  checkout-lfs:
    name: Checkout LFS Files
    runs-on: ubuntu-22.04
    steps:
      - name: Checkout code with LFS
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          lfs: true

      - name: Checkout LFS objects
        run: git lfs checkout

      - name: Upload testdata as artifact
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        with:
          name: testdata-lfs
          path: testdata/
          retention-days: 1

  # ===========================================================================
  # Doc Tests (run once on x86_64, in parallel with other tests)
  # ===========================================================================
  doc-tests:
    name: Doc Tests
    runs-on: ubuntu-22.04
    needs: checkout-lfs
    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          lfs: true  # Doc tests use include_str!/include_bytes! which need LFS at compile time

      - name: Install OpenCV build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y clang libclang-dev libopencv-dev

      - name: Set up Rust stable toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          toolchain: stable

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5  # v2.8.2
        with:
          shared-key: rust-x86_64-doc
          cache-on-failure: true

      - name: Run doc tests
        run: cargo test --doc --workspace --all-features

  # ===========================================================================
  # Build and Test on x86_64 (GitHub-hosted runner with Docker)
  # ===========================================================================
  build-and-test-x86:
    name: Build & Test (x86_64)
    runs-on: ubuntu-22.04
    needs: checkout-lfs
    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          fetch-depth: 0
          lfs: false  # LFS files downloaded separately

      - name: Download LFS testdata
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: testdata-lfs
          path: testdata/

      - name: Install OpenCV build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y clang libclang-dev libopencv-dev

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set up Python virtual environment
        run: |
          python3 -m venv venv
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH
          venv/bin/pip install --upgrade pip setuptools wheel
          venv/bin/pip install maturin[patchelf] slipcover pytest pytest-timeout pytest-benchmark
          venv/bin/pip install tensorflow pyyaml numpy pillow opencv-python-headless psutil

      - name: Set up Rust stable toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          toolchain: stable
          components: llvm-tools-preview, clippy, rustfmt

      - name: Set up Rust nightly toolchain (for Python builds)
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # nightly
        with:
          toolchain: nightly
          components: llvm-tools-preview, rustfmt, clippy

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5  # v2.8.2
        with:
          shared-key: rust-${{ matrix.platform.name }}
          cache-on-failure: true

      - name: Install cargo tools
        uses: taiki-e/install-action@493d7f216ecab2af0602481ce809ab2c72836fa1  # v2.62.62
        with:
          tool: cargo-llvm-cov@0.6.16,cargo-nextest

      - name: Check Rust formatting
        run: cargo +nightly fmt --all -- --check 2>/dev/null || cargo fmt --all -- --check

      - name: Run Clippy
        # Use default,opencv features; exclude g2d_test_formats,dma_test_formats (on-target only)
        run: cargo clippy --workspace --all-targets --features default,opencv -- -D warnings

      - name: Set up coverage instrumentation
        run: .github/scripts/setup-coverage-env.sh

      - name: Build Python bindings with coverage instrumentation
        run: |
          source /tmp/coverage-env.sh
          venv/bin/maturin build \
            --manifest-path crates/python/Cargo.toml \
            --out target/wheels \
            --profile profiling \
            --features python-abi311
          venv/bin/pip install target/wheels/*.whl

      - name: Run Rust tests with coverage
        run: |
          set -o pipefail
          # Run tests but don't generate report yet - we'll combine with Python test coverage
          # Use default,opencv features; exclude g2d_test_formats,dma_test_formats (on-target only)
          cargo llvm-cov nextest --cargo-profile profiling --features default,opencv --workspace \
            --no-report \
            2>&1 | tee target/test-metrics-rust-x86_64.txt

      - name: Build C API library
        run: cargo build --release -p edgefirst-hal-capi

      - name: Run C API tests
        run: |
          set -o pipefail
          cd crates/capi/tests
          make test 2>&1 | tee ../../../target/test-metrics-capi-x86_64.txt

      - name: Run Python tests with coverage
        run: |
          set -o pipefail
          # Source coverage env so Python tests generate profraw for PyO3 bindings
          source /tmp/coverage-env.sh
          # Python tests exercise PyO3 bindings - profraw files generated from instrumented wheel
          venv/bin/python -m slipcover --xml --out target/coverage_python.xml \
            -m pytest tests/ -v --tb=short --junitxml=target/pytest_results.xml \
            2>&1 | tee target/test-metrics-python-x86_64.txt

      - name: Generate combined Rust coverage report
        run: |
          # Generate LCOV report combining Rust tests + Python tests (PyO3 bindings coverage)
          cargo llvm-cov report --profile profiling \
            --ignore-filename-regex '(\.cargo|/rustc/|/target/)' \
            --lcov --output-path target/coverage_rust.lcov
          echo "=== Coverage summary ==="
          echo "Source files in coverage: $(grep -c '^SF:' target/coverage_rust.lcov)"
          echo "PyO3 files with coverage:"
          grep '^SF:.*crates/python' target/coverage_rust.lcov || echo "  (none found)"
          echo "=== Sample coverage data for crates/python ==="
          # Show hit counts for PyO3 files to verify they're being exercised
          awk '/^SF:.*crates\/python/{found=1; file=$0} found && /^DA:/{print file": "$0} found && /^end_of_record/{found=0}' target/coverage_rust.lcov | head -20

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: coverage-x86_64
          path: |
            target/coverage_rust.lcov
            target/coverage_python.xml
          retention-days: 30

      - name: Upload test results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: test-results-x86_64
          path: |
            target/pytest_results.xml
            target/nextest/default/test-results.xml
            target/test-metrics-rust-x86_64.txt
            target/test-metrics-capi-x86_64.txt
            target/test-metrics-python-x86_64.txt
          retention-days: 30

      - name: Publish test results
        uses: EnricoMi/publish-unit-test-result-action@34d7c956a59aed1bfebf31df77b8de55db9bbaaf  # v2.21.0
        if: always()
        with:
          files: |
            target/pytest_results.xml
            target/nextest/default/test-results.xml
          check_name: Test Results (x86_64)
          comment_mode: always
          ignore_runs: true

  # ===========================================================================
  # Build and Test on aarch64 (Self-hosted runner WITHOUT Docker)
  # ===========================================================================
  build-and-test-arm:
    name: Build & Test (aarch64)
    runs-on: ubuntu-22.04-arm-private
    needs: checkout-lfs
    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          fetch-depth: 0
          lfs: false  # LFS files downloaded separately

      - name: Download LFS testdata
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: testdata-lfs
          path: testdata/

      - name: Install build dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y build-essential python3-dev clang libclang-dev libopencv-dev

      - name: Set up Python
        uses: actions/setup-python@a26af69be951a213d495a4c3e4e4022e16d87065  # v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Set PYO3_PYTHON environment variable
        run: echo "PYO3_PYTHON=$(which python3)" >> $GITHUB_ENV

      - name: Set up Python virtual environment
        run: |
          python3 -m venv venv
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH
          venv/bin/pip install --upgrade pip setuptools wheel
          venv/bin/pip install maturin[patchelf,zig] slipcover pytest pytest-timeout pytest-benchmark
          venv/bin/pip install tensorflow pyyaml numpy pillow opencv-python-headless psutil

      - name: Set up Rust stable toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          toolchain: stable
          components: llvm-tools-preview, clippy, rustfmt

      - name: Set up Rust nightly toolchain (for Python builds)
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # nightly
        with:
          toolchain: nightly
          components: llvm-tools-preview, rustfmt, clippy

      - name: Cache Rust dependencies
        uses: Swatinem/rust-cache@779680da715d629ac1d338a641029a2f4372abb5  # v2.8.2
        with:
          shared-key: rust-aarch64
          cache-on-failure: true

      - name: Install cargo tools
        uses: taiki-e/install-action@493d7f216ecab2af0602481ce809ab2c72836fa1  # v2.62.62
        with:
          tool: cargo-llvm-cov@0.6.16,cargo-nextest

      - name: Check Rust formatting
        run: cargo +nightly fmt --all -- --check 2>/dev/null || cargo fmt --all -- --check

      - name: Run Clippy
        # Use default,opencv features; exclude g2d_test_formats,dma_test_formats (on-target only)
        run: cargo clippy --workspace --all-targets --features default,opencv -- -D warnings

      - name: Set up coverage instrumentation
        run: .github/scripts/setup-coverage-env.sh

      - name: Build Python bindings with coverage instrumentation
        run: |
          source /tmp/coverage-env.sh
          # No zig/manylinux - target glibc (2.41) is newer than Ubuntu 22.04 (2.35)
          venv/bin/maturin build \
            --manifest-path crates/python/Cargo.toml \
            --out target/wheels \
            --profile profiling \
            --features python-abi311
          venv/bin/pip install target/wheels/*.whl

      - name: Run Rust tests with coverage
        run: |
          set -o pipefail
          # Run tests but don't generate report yet - we'll combine with Python test coverage
          # Use default,opencv features; exclude g2d_test_formats,dma_test_formats (on-target only)
          cargo llvm-cov nextest --cargo-profile profiling --features default,opencv --workspace \
            --no-report \
            2>&1 | tee target/test-metrics-rust-aarch64.txt

      - name: Build C API library
        run: cargo build --release -p edgefirst-hal-capi

      - name: Run C API tests
        run: |
          set -o pipefail
          cd crates/capi/tests
          make test 2>&1 | tee ../../../target/test-metrics-capi-aarch64.txt

      - name: Run Python tests with coverage
        run: |
          set -o pipefail
          # Source coverage env so Python tests generate profraw for PyO3 bindings
          source /tmp/coverage-env.sh
          # Python tests exercise PyO3 bindings - profraw files generated from instrumented wheel
          venv/bin/python -m slipcover --xml --out target/coverage_python.xml \
            -m pytest tests/ -v --tb=short --junitxml=target/pytest_results.xml \
            2>&1 | tee target/test-metrics-python-aarch64.txt

      - name: Generate combined Rust coverage report
        run: |
          # Generate LCOV report combining Rust tests + Python tests (PyO3 bindings coverage)
          cargo llvm-cov report --profile profiling \
            --ignore-filename-regex '(\.cargo|/rustc/|/target/)' \
            --lcov --output-path target/coverage_rust.lcov
          echo "=== Coverage summary ==="
          echo "Source files in coverage: $(grep -c '^SF:' target/coverage_rust.lcov)"
          echo "PyO3 files with coverage:"
          grep '^SF:.*crates/python' target/coverage_rust.lcov || echo "  (none found)"
          echo "=== Sample coverage data for crates/python ==="
          # Show hit counts for PyO3 files to verify they're being exercised
          awk '/^SF:.*crates\/python/{found=1; file=$0} found && /^DA:/{print file": "$0} found && /^end_of_record/{found=0}' target/coverage_rust.lcov | head -20

      - name: Build instrumented test binaries for hardware
        run: |
          source /tmp/coverage-env.sh
          cargo nextest run --workspace --all-features --no-run --cargo-profile profiling
          mkdir -p hardware-test-binaries
          find target/llvm-cov-target/profiling/deps/ -maxdepth 1 -type f -executable \
            ! -name "*.d" ! -name "*.rlib" ! -name "*.rmeta" ! -name "*.so" \
            -exec cp {} hardware-test-binaries/ \; 2>/dev/null || true
          find target/profiling/deps/ -maxdepth 1 -type f -executable \
            ! -name "*.d" ! -name "*.rlib" ! -name "*.rmeta" ! -name "*.so" \
            -exec cp {} hardware-test-binaries/ \; 2>/dev/null || true
          echo "Instrumented test binaries:"
          ls -la hardware-test-binaries/ || echo "No test binaries found"

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: coverage-aarch64
          path: |
            target/coverage_rust.lcov
            target/coverage_python.xml
          retention-days: 30

      - name: Upload test results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: test-results-aarch64
          path: |
            target/pytest_results.xml
            target/nextest/default/test-results.xml
            target/test-metrics-rust-aarch64.txt
            target/test-metrics-capi-aarch64.txt
            target/test-metrics-python-aarch64.txt
          retention-days: 30

      - name: Build C API test binaries for hardware
        run: |
          # Build C API library (release)
          cargo build --release -p edgefirst-hal-capi
          # Build C tests
          cd crates/capi/tests
          make all
          cd ../../..
          # Copy C API artifacts for hardware testing
          mkdir -p hardware-capi-tests
          cp target/release/libedgefirst_hal.so hardware-capi-tests/
          cp target/release/libedgefirst_hal.a hardware-capi-tests/ 2>/dev/null || true
          cp crates/capi/tests/build/test_all hardware-capi-tests/
          echo "C API test artifacts:"
          ls -la hardware-capi-tests/

      - name: Upload hardware test artifacts (binaries + wheels only)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: hardware-test-binaries
          path: |
            target/profiling/*.so*
            target/profiling/deps/*.so*
            target/wheels/*.whl
            hardware-test-binaries/
            hardware-capi-tests/
          retention-days: 7

      - name: Upload coverage instrumented binaries (for profraw processing)
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: coverage-binaries-aarch64
          path: |
            target/llvm-cov-target/profiling/deps/*
          retention-days: 7

  # ===========================================================================
  # Hardware Testing + Benchmarks on NXP i.MX8M Plus
  # ===========================================================================
  hardware-test:
    name: Hardware Test (imx8mp)
    needs: [checkout-lfs, build-and-test-arm]
    runs-on: nxp-imx8mp-latest
    permissions:
      contents: read
      checks: write
      pull-requests: write

    steps:
      - name: Clean workspace
        run: |
          rm -rf build/ venv/ target/ rust-tests/ benchmark-results/ testdata/ 2>/dev/null || true
          find . -name "*.gcda" -o -name "*.profraw" -delete 2>/dev/null || true

      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          lfs: false  # LFS files downloaded separately

      - name: Download LFS testdata
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: testdata-lfs
          path: testdata/

      - name: Download aarch64 test artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: hardware-test-binaries
          path: .  # Download to workspace root to preserve directory structure

      - name: Set up Python virtual environment
        run: |
          python3 -m venv venv
          echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH
          venv/bin/pip install --upgrade pip setuptools wheel
          venv/bin/pip install slipcover pytest pytest-timeout pytest-benchmark tensorflow pyyaml numpy pillow opencv-python-headless psutil
          # Install Python bindings from pre-built wheel (built with profiling profile on aarch64)
          venv/bin/pip install target/wheels/*.whl

      - name: Debug environment info
        run: |
          echo "=== System Info ===" && uname -a
          echo "=== DMA heap ===" && ls -la /dev/dma_heap/ 2>/dev/null || echo "Not found"
          echo "=== G2D ===" && ls -la /dev/galcore 2>/dev/null || echo "Not found"
          echo "=== Downloaded artifacts ===" && find . -name "*.so*" -o -name "profiling" -type d 2>/dev/null || echo "Not found"
          echo "=== Test binaries ===" && ls -la hardware-test-binaries/ 2>/dev/null || echo "Not found"

      - name: Run Python tests with coverage
        env:
          LLVM_PROFILE_FILE: ${{ github.workspace }}/build/profraw/%p-%m.profraw
        run: |
          set -o pipefail
          mkdir -p build/profraw
          export LD_LIBRARY_PATH=$(pwd)/target/profiling:$LD_LIBRARY_PATH
          venv/bin/python -m slipcover --xml --out build/coverage_python.xml \
            -m pytest tests/ -v --tb=short --junitxml=build/pytest_results.xml \
            2>&1 | tee build/test-metrics-python-imx8mp.txt

      - name: Run pre-built Rust tests
        env:
          LD_LIBRARY_PATH: ${{ github.workspace }}/target/profiling:$LD_LIBRARY_PATH
          LLVM_PROFILE_FILE: ${{ github.workspace }}/build/profraw/rust-%p-%m.profraw
        run: |
          set -o pipefail
          mkdir -p build/rust-test-results build/profraw
          chmod +x hardware-test-binaries/* 2>/dev/null || true
          TEST_FAILED=0
          for test_bin in hardware-test-binaries/*; do
            if [ -x "$test_bin" ] && [ -f "$test_bin" ]; then
              # Skip .so files (proc-macro shared libraries)
              if [[ "$test_bin" == *.so ]]; then
                continue
              fi
              test_name=$(basename "$test_bin")
              echo "=== Running $test_name ==="
              if ! "$test_bin" --test-threads=1 2>&1 | tee "build/rust-test-results/${test_name}.txt"; then
                echo "FAILED: $test_name"
                TEST_FAILED=1
              fi
            fi
          done
          [ $TEST_FAILED -eq 0 ] || exit 1

      - name: Run C API tests
        run: |
          set -o pipefail
          if [ -d "hardware-capi-tests" ] && [ -f "hardware-capi-tests/test_all" ]; then
            echo "=== Running C API tests on hardware ==="
            chmod +x hardware-capi-tests/test_all
            export LD_LIBRARY_PATH=$(pwd)/hardware-capi-tests:$LD_LIBRARY_PATH
            hardware-capi-tests/test_all 2>&1 | tee build/test-metrics-capi-imx8mp.txt
          else
            echo "C API test binary not found, skipping"
          fi

      - name: Run benchmarks (main branch only)
        if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
        run: |
          mkdir -p benchmark-results
          echo "=== System Info ===" > benchmark-results/system-info.txt
          uname -a >> benchmark-results/system-info.txt
          cat /proc/cpuinfo | head -30 >> benchmark-results/system-info.txt
          free -h >> benchmark-results/system-info.txt
          export LD_LIBRARY_PATH=$(pwd)/target/profiling:$LD_LIBRARY_PATH
          if [ -f "benchmarks/benchmark.py" ]; then
            venv/bin/python benchmarks/benchmark.py --json benchmark-results/benchmark.json
          else
            venv/bin/python -c "
          import time, json, numpy as np
          results = {'benchmarks': {}}
          start = time.perf_counter()
          for _ in range(100):
              img = np.random.randint(0, 255, (1080, 1920, 3), dtype=np.uint8)
          elapsed = time.perf_counter() - start
          results['benchmarks']['numpy_random_1080p'] = {'mean': elapsed/100*1000, 'unit': 'ms'}
          with open('benchmark-results/benchmark.json', 'w') as f:
              json.dump(results, f, indent=2)
          print('Basic benchmark completed')
          "
          fi

      - name: Generate JUnit XML from Rust results
        if: always()
        run: python3 scripts/generate_junit_xml.py build/rust-test-results build/rust_hardware_results.xml

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: coverage-imx8mp
          path: |
            build/coverage_python.xml
            build/profraw/
          retention-days: 30

      - name: Upload test results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always()
        with:
          name: test-results-imx8mp
          path: |
            build/pytest_results.xml
            build/rust_hardware_results.xml
            build/test-metrics-python-imx8mp.txt
            build/test-metrics-capi-imx8mp.txt
          retention-days: 30

      - name: Upload benchmark results
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        if: always() && (github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch')
        with:
          name: benchmark-results
          path: benchmark-results/
          retention-days: 90

      # Note: imx8mp is an embedded device without Docker/full Python tooling
      # Test results are uploaded as artifacts; skip the publish action here
      - name: Test results summary (imx8mp)
        if: always()
        run: |
          echo "## Hardware Test Results (imx8mp)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          if [ -f build/pytest_results.xml ]; then
            echo "- Python tests completed - see artifacts for details" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f build/rust_hardware_results.xml ]; then
            echo "- Rust tests completed - see artifacts for details" >> $GITHUB_STEP_SUMMARY
          fi
          if [ -f build/test-metrics-capi-imx8mp.txt ]; then
            echo "- C API tests completed - see artifacts for details" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Generate benchmark summary
        if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'
        run: python3 scripts/benchmark_summary.py benchmark-results/benchmark.json >> $GITHUB_STEP_SUMMARY

  # ===========================================================================
  # Process Hardware Coverage (profraw -> LCOV)
  # ===========================================================================
  process-hardware-coverage:
    name: Process Hardware Coverage
    needs: [build-and-test-arm, hardware-test]
    runs-on: ubuntu-22.04-arm-private
    permissions:
      contents: read

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4

      - name: Download coverage instrumented binaries
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: coverage-binaries-aarch64
          path: target/llvm-cov-target/profiling/deps/

      - name: Download imx8mp coverage (contains profraw files)
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          name: coverage-imx8mp
          path: coverage-imx8mp/

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@6d9817901c499d6b02debbb57edb38d33daa680b  # stable
        with:
          toolchain: stable
          components: llvm-tools-preview

      - name: Process Rust profraw files
        run: |
          PROFRAW_COUNT=$(find coverage-imx8mp/ -name "*.profraw" 2>/dev/null | wc -l)
          echo "Found $PROFRAW_COUNT profraw files"

          if [ "$PROFRAW_COUNT" -eq 0 ]; then
            echo "No profraw files, creating empty coverage"
            mkdir -p output && echo "" > output/coverage_rust_imx8mp.lcov
            exit 0
          fi

          TOOLCHAIN_ROOT=$(rustc --print sysroot)
          LLVM_PROFDATA=$(find "$TOOLCHAIN_ROOT" -name "llvm-profdata" -type f | head -1)
          LLVM_COV=$(find "$TOOLCHAIN_ROOT" -name "llvm-cov" -type f | head -1)

          mkdir -p output
          "$LLVM_PROFDATA" merge -sparse $(find coverage-imx8mp/ -name "*.profraw") -o output/imx8mp.profdata

          OBJECT_FILES=""
          for obj in $(find target/llvm-cov-target -type f ! -name "*.d" ! -name "*.rlib" ! -name "*.rmeta" 2>/dev/null); do
            if file "$obj" 2>/dev/null | grep -q "ELF"; then
              [ -z "$OBJECT_FILES" ] && OBJECT_FILES="$obj" || OBJECT_FILES="$OBJECT_FILES --object=$obj"
            fi
          done

          if [ -z "$OBJECT_FILES" ]; then
            echo "No ELF binaries found, creating empty coverage"
            echo "" > output/coverage_rust_imx8mp.lcov
            exit 0
          fi

          "$LLVM_COV" export --format=lcov --instr-profile=output/imx8mp.profdata \
            --ignore-filename-regex='/.cargo/registry|/rustc/' \
            --path-equivalence="/home/runner/work/hal/hal","${{ github.workspace }}" \
            $OBJECT_FILES > output/coverage_rust_imx8mp.lcov 2>/dev/null || echo "" > output/coverage_rust_imx8mp.lcov

          echo "Generated coverage_rust_imx8mp.lcov: $(wc -l < output/coverage_rust_imx8mp.lcov) lines"

      - name: Upload processed coverage
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02  # v4
        with:
          name: coverage-imx8mp-processed
          path: |
            output/coverage_rust_imx8mp.lcov
            coverage-imx8mp/build/coverage_python.xml
          retention-days: 30

  # ===========================================================================
  # SonarCloud Analysis
  # ===========================================================================
  sonarcloud:
    name: SonarCloud Analysis
    needs: [doc-tests, build-and-test-x86, build-and-test-arm, hardware-test, process-hardware-coverage]
    runs-on: ubuntu-22.04
    if: github.event_name == 'push' || github.event.pull_request.head.repo.full_name == github.repository
    permissions:
      contents: read
      pull-requests: read

    steps:
      - name: Checkout code
        uses: actions/checkout@34e114876b0b11c390a56381ad16ebd13914f8d5  # v4
        with:
          fetch-depth: 0

      - name: Download all coverage artifacts
        uses: actions/download-artifact@d3f86a106a0bac45b974a628896c90dbdf5c8093  # v4
        with:
          pattern: coverage-*
          path: coverage/

      - name: Organize coverage files
        run: |
          echo "=== Downloaded coverage artifacts ==="
          find coverage/ -type f

          echo "=== Fixing Python coverage paths ==="
          for xml in $(find coverage/ -name "coverage_python.xml" -type f); do
            python3 scripts/fix_coverage_paths.py "$xml" tests
          done

          RUST_REPORTS=$(find coverage/ -name "*.lcov" | tr '\n' ',' | sed 's/,$//')
          PYTHON_REPORTS=$(find coverage/ -name "coverage_python.xml" | tr '\n' ',' | sed 's/,$//')

          echo "Rust: $RUST_REPORTS"
          echo "Python: $PYTHON_REPORTS"
          echo "RUST_COVERAGE_PATHS=$RUST_REPORTS" >> $GITHUB_ENV
          echo "PYTHON_COVERAGE_PATHS=$PYTHON_REPORTS" >> $GITHUB_ENV

      - name: Run SonarCloud scan
        uses: SonarSource/sonarqube-scan-action@fd88b7d7ccbaefd23d8f36f73b59db7a3d246602  # v6.0.0
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >-
            "-Dsonar.rust.lcov.reportPaths=${{ env.RUST_COVERAGE_PATHS }}"
            "-Dsonar.python.coverage.reportPaths=${{ env.PYTHON_COVERAGE_PATHS }}"
            "-Dsonar.verbose=true"

      - name: Generate summary
        if: always()
        run: |
          {
            echo "# HAL Test & Coverage Summary"
            echo ""
            echo "## Test Platforms"
            echo "| Platform | Architecture | Tests |"
            echo "|----------|--------------|-------|"
            echo "| Ubuntu 22.04 | x86_64 | Rust, Python, C API |"
            echo "| Ubuntu 22.04 | aarch64 | Rust, Python, C API |"
            echo "| NXP i.MX8M Plus | aarch64 | Rust, Python, C API (DMA, G2D) |"
            echo ""
            python3 scripts/coverage_summary.py --github-actions
            echo ""
            echo "## SonarCloud"
            echo "- [Dashboard](https://sonarcloud.io/summary/overall?id=EdgeFirstAI_hal&branch=${{ github.ref_name }})"
          } >> $GITHUB_STEP_SUMMARY
